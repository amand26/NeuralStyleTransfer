{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "images/15_style_transfer_flowchart.png",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "Image('images/15_style_transfer_flowchart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xu2SVpFJjmJr"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vgg16.data_dir = 'vgg16/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading VGG16 Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "vgg16.maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(filename, max_size=None):\n",
    "    image = PIL.Image.open(filename)\n",
    "\n",
    "    if max_size is not None:\n",
    "        # Calculate the appropriate rescale-factor for\n",
    "        # ensuring a max height and width, while keeping\n",
    "        # the proportion between them.\n",
    "        factor = max_size / np.max(image.size)\n",
    "    \n",
    "        # Scale the image's height and width.\n",
    "        size = np.array(image.size) * factor\n",
    "\n",
    "        # The size is now floating-point because it was scaled.\n",
    "        # But PIL requires the size to be integers.\n",
    "        size = size.astype(int)\n",
    "\n",
    "        # Resize the image.\n",
    "        image = image.resize(size, PIL.Image.LANCZOS)\n",
    "\n",
    "    # Convert to numpy floating-point array.\n",
    "    return np.float32(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(image, filename):\n",
    "    # Ensure the pixel-values are between 0 and 255.\n",
    "    image = np.clip(image, 0.0, 255.0)\n",
    "    \n",
    "    # Convert to bytes.\n",
    "    image = image.astype(np.uint8)\n",
    "    \n",
    "    # Write the image-file in jpeg-format.\n",
    "    with open(filename, 'wb') as file:\n",
    "        PIL.Image.fromarray(image).save(file, 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(content_image, style_image, mixed_image):\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    # Use interpolation to smooth pixels?\n",
    "    smooth = True\n",
    "    \n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'sinc'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    # Plot the content-image.\n",
    "    # Note that the pixel-values are normalized to\n",
    "    # the [0.0, 1.0] range by dividing with 255.\n",
    "    ax = axes.flat[0]\n",
    "    ax.imshow(content_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Content\")\n",
    "\n",
    "    # Plot the mixed-image.\n",
    "    ax = axes.flat[1]\n",
    "    ax.imshow(mixed_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Mixed\")\n",
    "\n",
    "    # Plot the style-image\n",
    "    ax = axes.flat[2]\n",
    "    ax.imshow(style_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"Style\")\n",
    "\n",
    "    # Remove ticks from all the plots.\n",
    "    for ax in axes.flat:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(a, b):\n",
    "    return tf.reduce_mean(tf.square(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_content_loss(session, model, content_image, layer_ids):\n",
    "    \"\"\"\n",
    "    Create the loss-function for the content-image.\n",
    "    \n",
    "    Parameters:\n",
    "    session: An open TensorFlow session for running the model's graph.\n",
    "    model: The model, e.g. an instance of the VGG16-class.\n",
    "    content_image: Numpy float array with the content-image.\n",
    "    layer_ids: List of integer id's for the layers to use in the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a feed-dict with the content-image.\n",
    "    feed_dict = model.create_feed_dict(image=content_image)\n",
    "\n",
    "    # Get references to the tensors for the given layers.\n",
    "    layers = model.get_layer_tensors(layer_ids)\n",
    "\n",
    "    # Calculate the output values of those layers when\n",
    "    # feeding the content-image to the model.\n",
    "    values = session.run(layers, feed_dict=feed_dict)\n",
    "\n",
    "    # Set the model's graph as the default so we can add\n",
    "    # computational nodes to it. It is not always clear\n",
    "    # when this is necessary in TensorFlow, but if you\n",
    "    # want to re-use this code then it may be necessary.\n",
    "    with model.graph.as_default():\n",
    "        # Initialize an empty list of loss-functions.\n",
    "        layer_losses = []\n",
    "    \n",
    "        # For each layer and its corresponding values\n",
    "        # for the content-image.\n",
    "        for value, layer in zip(values, layers):\n",
    "            # These are the values that are calculated\n",
    "            # for this layer in the model when inputting\n",
    "            # the content-image. Wrap it to ensure it\n",
    "            # is a const - although this may be done\n",
    "            # automatically by TensorFlow.\n",
    "            value_const = tf.constant(value)\n",
    "\n",
    "            # The loss-function for this layer is the\n",
    "            # Mean Squared Error between the layer-values\n",
    "            # when inputting the content- and mixed-images.\n",
    "            # Note that the mixed-image is not calculated\n",
    "            # yet, we are merely creating the operations\n",
    "            # for calculating the MSE between those two.\n",
    "            loss = mean_squared_error(layer, value_const)\n",
    "\n",
    "            # Add the loss-function for this layer to the\n",
    "            # list of loss-functions.\n",
    "            layer_losses.append(loss)\n",
    "\n",
    "        # The combined loss for all layers is just the average.\n",
    "        # The loss-functions could be weighted differently for\n",
    "        # each layer. You can try it and see what happens.\n",
    "        total_loss = tf.reduce_mean(layer_losses)\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(tensor):\n",
    "    shape = tensor.get_shape()\n",
    "    \n",
    "    # Get the number of feature channels for the input tensor,\n",
    "    # which is assumed to be from a convolutional layer with 4-dim.\n",
    "    num_channels = int(shape[3])\n",
    "\n",
    "    # Reshape the tensor so it is a 2-dim matrix. This essentially\n",
    "    # flattens the contents of each feature-channel.\n",
    "    matrix = tf.reshape(tensor, shape=[-1, num_channels])\n",
    "    \n",
    "    # Calculate the Gram-matrix as the matrix-product of\n",
    "    # the 2-dim matrix with itself. This calculates the\n",
    "    # dot-products of all combinations of the feature-channels.\n",
    "    gram = tf.matmul(tf.transpose(matrix), matrix)\n",
    "\n",
    "    return gram                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_style_loss(session, model, style_image, layer_ids):\n",
    "    \"\"\"\n",
    "    Create the loss-function for the style-image.\n",
    "    \n",
    "    Parameters:\n",
    "    session: An open TensorFlow session for running the model's graph.\n",
    "    model: The model, e.g. an instance of the VGG16-class.\n",
    "    style_image: Numpy float array with the style-image.\n",
    "    layer_ids: List of integer id's for the layers to use in the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a feed-dict with the style-image.\n",
    "    feed_dict = model.create_feed_dict(image=style_image)\n",
    "\n",
    "    # Get references to the tensors for the given layers.\n",
    "    layers = model.get_layer_tensors(layer_ids)\n",
    "\n",
    "    # Set the model's graph as the default so we can add\n",
    "    # computational nodes to it. It is not always clear\n",
    "    # when this is necessary in TensorFlow, but if you\n",
    "    # want to re-use this code then it may be necessary.\n",
    "    with model.graph.as_default():\n",
    "        # Construct the TensorFlow-operations for calculating\n",
    "        # the Gram-matrices for each of the layers.\n",
    "        gram_layers = [gram_matrix(layer) for layer in layers]\n",
    "\n",
    "        # Calculate the values of those Gram-matrices when\n",
    "        # feeding the style-image to the model.\n",
    "        values = session.run(gram_layers, feed_dict=feed_dict)\n",
    "\n",
    "        # Initialize an empty list of loss-functions.\n",
    "        layer_losses = []\n",
    "    \n",
    "        # For each Gram-matrix layer and its corresponding values.\n",
    "        for value, gram_layer in zip(values, gram_layers):\n",
    "            # These are the Gram-matrix values that are calculated\n",
    "            # for this layer in the model when inputting the\n",
    "            # style-image. Wrap it to ensure it is a const,\n",
    "            # although this may be done automatically by TensorFlow.\n",
    "            value_const = tf.constant(value)\n",
    "\n",
    "            # The loss-function for this layer is the\n",
    "            # Mean Squared Error between the Gram-matrix values\n",
    "            # for the content- and mixed-images.\n",
    "            # Note that the mixed-image is not calculated\n",
    "            # yet, we are merely creating the operations\n",
    "            # for calculating the MSE between those two.\n",
    "            loss = mean_squared_error(gram_layer, value_const)\n",
    "\n",
    "            # Add the loss-function for this layer to the\n",
    "            # list of loss-functions.\n",
    "            layer_losses.append(loss)\n",
    "\n",
    "        # The combined loss for all layers is just the average.\n",
    "        # The loss-functions could be weighted differently for\n",
    "        # each layer. You can try it and see what happens.\n",
    "        total_loss = tf.reduce_mean(layer_losses)\n",
    "        \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_denoise_loss(model):\n",
    "    loss = tf.reduce_sum(tf.abs(model.input[:,1:,:,:] - model.input[:,:-1,:,:])) + \\\n",
    "           tf.reduce_sum(tf.abs(model.input[:,:,1:,:] - model.input[:,:,:-1,:]))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_transfer(content_image, style_image,\n",
    "                   content_layer_ids, style_layer_ids,\n",
    "                   weight_content=1.5, weight_style=10.0,\n",
    "                   weight_denoise=0.3,\n",
    "                   num_iterations=120, step_size=10.0):\n",
    "    \"\"\"\n",
    "    Use gradient descent to find an image that minimizes the\n",
    "    loss-functions of the content-layers and style-layers. This\n",
    "    should result in a mixed-image that resembles the contours\n",
    "    of the content-image, and resembles the colours and textures\n",
    "    of the style-image.\n",
    "    \n",
    "    Parameters:\n",
    "    content_image: Numpy 3-dim float-array with the content-image.\n",
    "    style_image: Numpy 3-dim float-array with the style-image.\n",
    "    content_layer_ids: List of integers identifying the content-layers.\n",
    "    style_layer_ids: List of integers identifying the style-layers.\n",
    "    weight_content: Weight for the content-loss-function.\n",
    "    weight_style: Weight for the style-loss-function.\n",
    "    weight_denoise: Weight for the denoising-loss-function.\n",
    "    num_iterations: Number of optimization iterations to perform.\n",
    "    step_size: Step-size for the gradient in each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an instance of the VGG16-model. This is done\n",
    "    # in each call of this function, because we will add\n",
    "    # operations to the graph so it can grow very large\n",
    "    # and run out of RAM if we keep using the same instance.\n",
    "    model = vgg16.VGG16()\n",
    "\n",
    "    # Create a TensorFlow-session.\n",
    "    session = tf.InteractiveSession(graph=model.graph)\n",
    "\n",
    "    # Print the names of the content-layers.\n",
    "    print(\"Content layers:\")\n",
    "    print(model.get_layer_names(content_layer_ids))\n",
    "    print()\n",
    "\n",
    "    # Print the names of the style-layers.\n",
    "    print(\"Style layers:\")\n",
    "    print(model.get_layer_names(style_layer_ids))\n",
    "    print()\n",
    "\n",
    "    # Create the loss-function for the content-layers and -image.\n",
    "    loss_content = create_content_loss(session=session,\n",
    "                                       model=model,\n",
    "                                       content_image=content_image,\n",
    "                                       layer_ids=content_layer_ids)\n",
    "\n",
    "    # Create the loss-function for the style-layers and -image.\n",
    "    loss_style = create_style_loss(session=session,\n",
    "                                   model=model,\n",
    "                                   style_image=style_image,\n",
    "                                   layer_ids=style_layer_ids)    \n",
    "\n",
    "    # Create the loss-function for the denoising of the mixed-image.\n",
    "    loss_denoise = create_denoise_loss(model)\n",
    "\n",
    "    # Create TensorFlow variables for adjusting the values of\n",
    "    # the loss-functions. This is explained below.\n",
    "    adj_content = tf.Variable(1e-10, name='adj_content')\n",
    "    adj_style = tf.Variable(1e-10, name='adj_style')\n",
    "    adj_denoise = tf.Variable(1e-10, name='adj_denoise')\n",
    "\n",
    "    # Initialize the adjustment values for the loss-functions.\n",
    "    session.run([adj_content.initializer,\n",
    "                 adj_style.initializer,\n",
    "                 adj_denoise.initializer])\n",
    "\n",
    "    # Create TensorFlow operations for updating the adjustment values.\n",
    "    # These are basically just the reciprocal values of the\n",
    "    # loss-functions, with a small value 1e-10 added to avoid the\n",
    "    # possibility of division by zero.\n",
    "    update_adj_content = adj_content.assign(1.0 / (loss_content + 1e-10))\n",
    "    update_adj_style = adj_style.assign(1.0 / (loss_style + 1e-10))\n",
    "    update_adj_denoise = adj_denoise.assign(1.0 / (loss_denoise + 1e-10))\n",
    "\n",
    "    # This is the weighted loss-function that we will minimize\n",
    "    # below in order to generate the mixed-image.\n",
    "    # Because we multiply the loss-values with their reciprocal\n",
    "    # adjustment values, we can use relative weights for the\n",
    "    # loss-functions that are easier to select, as they are\n",
    "    # independent of the exact choice of style- and content-layers.\n",
    "    loss_combined = weight_content * adj_content * loss_content + \\\n",
    "                    weight_style * adj_style * loss_style + \\\n",
    "                    weight_denoise * adj_denoise * loss_denoise\n",
    "\n",
    "    # Use TensorFlow to get the mathematical function for the\n",
    "    # gradient of the combined loss-function with regard to\n",
    "    # the input image.\n",
    "    gradient = tf.gradients(loss_combined, model.input)\n",
    "\n",
    "    # List of tensors that we will run in each optimization iteration.\n",
    "    run_list = [gradient, update_adj_content, update_adj_style, \\\n",
    "                update_adj_denoise]\n",
    "\n",
    "    # The mixed-image is initialized with random noise.\n",
    "    # It is the same size as the content-image.\n",
    "    mixed_image = np.random.rand(*content_image.shape) + 128\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Create a feed-dict with the mixed-image.\n",
    "        feed_dict = model.create_feed_dict(image=mixed_image)\n",
    "\n",
    "        # Use TensorFlow to calculate the value of the\n",
    "        # gradient, as well as updating the adjustment values.\n",
    "        grad, adj_content_val, adj_style_val, adj_denoise_val \\\n",
    "        = session.run(run_list, feed_dict=feed_dict)\n",
    "\n",
    "        # Reduce the dimensionality of the gradient.\n",
    "        grad = np.squeeze(grad)\n",
    "\n",
    "        # Scale the step-size according to the gradient-values.\n",
    "        step_size_scaled = step_size / (np.std(grad) + 1e-8)\n",
    "\n",
    "        # Update the image by following the gradient.\n",
    "        mixed_image -= grad * step_size_scaled\n",
    "\n",
    "        # Ensure the image has valid pixel-values between 0 and 255.\n",
    "        mixed_image = np.clip(mixed_image, 0.0, 255.0)\n",
    "\n",
    "        # Print a little progress-indicator.\n",
    "        print(\". \", end=\"\")\n",
    "\n",
    "        # Display status once every 10 iterations, and the last.\n",
    "        if (i % 5 == 0) or (i == num_iterations - 1):\n",
    "            print()\n",
    "            print(\"Iteration:\", i)\n",
    "\n",
    "            # Print adjustment weights for loss-functions.\n",
    "            msg = \"Weight Adj. for Content: {0:.2e}, Style: {1:.2e}, Denoise: {2:.2e}\"\n",
    "            print(msg.format(adj_content_val, adj_style_val, adj_denoise_val))\n",
    "\n",
    "            # Plot the content-, style- and mixed-images.\n",
    "            plot_images(content_image=content_image,\n",
    "                        style_image=style_image,\n",
    "                        mixed_image=mixed_image)\n",
    "            \n",
    "    print()\n",
    "    print(\"Final image:\")\n",
    "\n",
    "    # Close the TensorFlow session to release its resources.\n",
    "    session.close()\n",
    "    \n",
    "    # Return the mixed-image.\n",
    "    return mixed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_filename = 'bros1.jpeg'\n",
    "content_image = load_image(content_filename, max_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_filename = 'style2.jpg'\n",
    "style_image = load_image(style_filename, max_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n"
     ]
    }
   ],
   "source": [
    "content_layer_ids = [4]\n",
    "print(content_layer_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The VGG16-model has 13 convolutional layers.\n",
    "# This selects all those layers as the style-layers.\n",
    "# This is somewhat slow to optimize.\n",
    "style_layer_ids = list(range(13))\n",
    "\n",
    "# You can also select a sub-set of the layers, e.g. like this:\n",
    "# style_layer_ids = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "img = style_transfer(content_image=content_image,\n",
    "                     style_image=style_image,\n",
    "                     content_layer_ids=content_layer_ids,\n",
    "                     style_layer_ids=style_layer_ids,\n",
    "                     weight_content=1.5,\n",
    "                     weight_style=10.0,\n",
    "                     weight_denoise=0.3,\n",
    "                     num_iterations=50,\n",
    "                     step_size=10.0)\n",
    "save_image(img, 'bros.jpeg')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
